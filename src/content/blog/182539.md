---
title: '“AI Slop” en los tribunales: abogados citan casos inexistentes creados por la IA'
description: 'Los despachos adoptan chatbots para redactar escritos y terminan presentando jurisprudencia que nunca existió, provocando sanciones y alarma en los jueces.'
pubDate: '2025-11-09T19:04:00Z'
heroImage: ''
---

El New York Times publica que la profesión jurídica se ha convertido, en los últimos meses, en un inesperado laboratorio de los fallos de la inteligencia artificial generativa. El caso más notorio ocurrió en un juzgado de quiebras de Texas, donde un letrado incluyó en una moción la sentencia “Brasher v. Stewart (1985)”. El problema: tal resolución jamás se dictó. La citación era fruto de una “alucinación” de un asistente de IA, fenómeno por el cual los modelos lingüísticos fabrican respuestas plausibles pero falsas.

Aunque los titulares se centran en episodios cómicos, detrás subyace un riesgo sistémico. La citación errónea puede pasar inadvertida y, en cascada, contaminar dictámenes, contratos o incluso sentencias. La tentación de delegar tareas rutinarias —búsqueda de precedentes o primeros borradores— crece a medida que los bufetes recortan costes y los clientes exigen inmediatez. Sin embargo, la tecnología aún carece de un mecanismo interno de verificación: produce texto con autoridad sintáctica, no con certeza jurídica.

Los jueces empiezan a reaccionar. Algunos tribunales federales han exigido ya que cualquier documento generado (o asistido) por IA venga acompañado de una certificación humana que confirme la autenticidad de las referencias. Otros estudian sanciones económicas a los profesionales reincidentes. Las facultades de Derecho, por su parte, aceleran cursos sobre “higiene de datos” y métodos de “fact-checking” automatizado.

Los proveedores de IA ensayan contramedidas: desde citaciones enlazadas a bases de datos oficiales hasta modos “verificar antes de responder”. Aun así, los expertos recuerdan que la responsabilidad última sigue siendo del abogado. “Usar IA no es distinto a emplear un pasante”, resume la profesora Rebecca Sandefur. “Si el pasante se equivoca, quien firma responde ante el juez”.

La lección para la abogacía parece clara: la inteligencia artificial puede ser un aliado potente, pero sin supervisión humana rigurosa se convierte en un riesgo reputacional y procesal nada menor.  

https://yro.slashdot.org/story/25/11/09/189220/ai-slop-in-court-filings-lawyers-keep-citing-fake-ai-hallucinated-cases